{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ModelEvaluationNLP (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAco6xj7DAn5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3687deef-ef46-48c5-de77-ac61df0879be"
      },
      "source": [
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "from nltk.tokenize import word_tokenize\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "!pip install -q \"nltk==3.4.5\"\n",
        "from google.colab import files\n",
        "import nltk\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "from nltk.lm import MLE\n",
        "from nltk.lm import Vocabulary\n",
        "import gensim\n",
        "from gensim.matutils import softcossim \n",
        "from gensim import corpora\n",
        "import gensim.downloader as api\n",
        "from gensim.utils import simple_preprocess"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuGrITAV8ZbS"
      },
      "source": [
        "model_ali = load_model('ali wong.h5')\n",
        "model_kenny=load_model('kenny sebastian.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HEw76rb92eL"
      },
      "source": [
        "def perplexity(self, text):\n",
        "  return pow(2.0, self.entropy(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "9cT7_eJTLkcg",
        "outputId": "c19f3ed2-4229-43ef-dc79-d4c723520298"
      },
      "source": [
        "data = pd.read_pickle(\"Cleaned_Transcript.pickle\")\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Artist</th>\n",
              "      <th>Title</th>\n",
              "      <th>Transcript</th>\n",
              "      <th>Cleaned_Transcript</th>\n",
              "      <th>Tokens</th>\n",
              "      <th>Cleaned_Artist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Chris Rock Total Blackout: The Tamborine Exten...</td>\n",
              "      <td>Chris Rock Total Blackout: The Tamborine Exten...</td>\n",
              "      <td>[Jimmy Fallon] Were you at the, uh, White Hous...</td>\n",
              "      <td>were you at the uh white house party yes i was...</td>\n",
              "      <td>[uh, white, house, party, yes, white, house, e...</td>\n",
              "      <td>chris rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bo Burnham: Words, Words, Words (2010) – Trans...</td>\n",
              "      <td>Bo Burnham: Words, Words, Words (2010) – Trans...</td>\n",
              "      <td>(Cheers and applause)\\nThank you.\\n(Laughter)\\...</td>\n",
              "      <td>thank you when i say hey you say ho hey ho hey...</td>\n",
              "      <td>[thank, say, hey, say, ho, hey, ho, hey, ho, b...</td>\n",
              "      <td>bo burnham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Vir Das: Outside in – The Lockdown Special (20...</td>\n",
              "      <td>Vir Das: Outside in – The Lockdown Special (20...</td>\n",
              "      <td>[soft piano music playing]\\n[Vir Das] What you...</td>\n",
              "      <td>what you are about to watch was not supposed t...</td>\n",
              "      <td>[watch, supposed, happen, completely, unscript...</td>\n",
              "      <td>vir das</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Larry the Cable Guy – Remain Seated (2020) – T...</td>\n",
              "      <td>Larry the Cable Guy – Remain Seated (2020) – T...</td>\n",
              "      <td>[Announcer] Ladies and gentlemen, Larry, The C...</td>\n",
              "      <td>ladies and gentlemen larry the cable guy all r...</td>\n",
              "      <td>[lady, gentleman, larry, cable, guy, right, th...</td>\n",
              "      <td>larry the cable guy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Craig Ferguson: Just Being Honest (2015) – Tra...</td>\n",
              "      <td>Craig Ferguson: Just Being Honest (2015) – Tra...</td>\n",
              "      <td>Watch the full show for free on YouTube\\n[bagp...</td>\n",
              "      <td>watch the full show for free on youtube its a ...</td>\n",
              "      <td>[watch, full, show, free, youtube, great, day,...</td>\n",
              "      <td>craig ferguson</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Artist  ...       Cleaned_Artist\n",
              "0  Chris Rock Total Blackout: The Tamborine Exten...  ...           chris rock\n",
              "1  Bo Burnham: Words, Words, Words (2010) – Trans...  ...           bo burnham\n",
              "2  Vir Das: Outside in – The Lockdown Special (20...  ...              vir das\n",
              "3  Larry the Cable Guy – Remain Seated (2020) – T...  ...  larry the cable guy\n",
              "4  Craig Ferguson: Just Being Honest (2015) – Tra...  ...       craig ferguson\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvFaahx3RRB7",
        "outputId": "341f0b23-9961-464d-9fc8-9e7f7b50e01e"
      },
      "source": [
        "np.random.seed(32)\n",
        "data = pd.read_pickle(\"Cleaned_Transcript.pickle\")\n",
        "data = data[['Cleaned_Artist', 'Cleaned_Transcript', 'Tokens']]\n",
        "data.columns = ['Artist', 'Transcript', 'Tokens']\n",
        "\n",
        "artist = 'kenny sebastian'\n",
        "data = data[artist == data['Artist']].reset_index().drop(\"index\", axis=1)\n",
        "data_list = []\n",
        "# with stop words\n",
        "stop_words = True\n",
        "if stop_words:\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    data['Tokens'] = data['Transcript'].apply(lambda x : [lemmatizer.lemmatize(w) for w in word_tokenize(x.lower())])\n",
        "\n",
        "data.iloc[:, 2].apply(lambda x : data_list.extend(x))\n",
        "print(\"Length of Data List: \", len(data_list))\n",
        "data = data_list\n",
        "del data_list\n",
        "\n",
        "n_words = len(data)\n",
        "unique_words = len(set(data))\n",
        "print('Total Words: %d' % n_words)\n",
        "print('Unique Words: %d\\n' % unique_words)\n",
        "\n",
        "length = 100 + 1\n",
        "lines = []\n",
        "for i in range(length, n_words):\n",
        "    seq = data[i - length : i]\n",
        "    line = ' '.join(seq)\n",
        "    lines.append(line)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of Data List:  178628\n",
            "Total Words: 178628\n",
            "Unique Words: 3632\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikR4rxaBRms0"
      },
      "source": [
        "def generate_texts(model, tokenizer, seed_text, n_words, seq_length):\n",
        "        print(\"_\"*150)\n",
        "        text = []\n",
        "        print(seed_text, end='\\n\\n')\n",
        "        for _ in range(n_words):\n",
        "            encoded = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "            encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
        "            y_predict = np.argmax(model.predict(encoded), axis=-1)\n",
        "\n",
        "            predicted_word = ''\n",
        "            for word, index in tokenizer.word_index.items():\n",
        "                if index == y_predict:\n",
        "                    predicted_word = word\n",
        "                    break\n",
        "            seed_text = seed_text + ' ' + predicted_word\n",
        "            text.append(predicted_word)\n",
        "        seed_text_tokenized=nltk.tokenize.word_tokenize(seed_text)\n",
        "        return (text,seed_text_tokenized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWDusg08Rg_a"
      },
      "source": [
        "index = 0\n",
        "def test_model(model, lines, input_length=100, stop_words=False):\n",
        "    global index\n",
        "    if index == 0:\n",
        "        index = np.random.randint(0, len(lines))\n",
        "\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(lines)\n",
        "    sequences = tokenizer.texts_to_sequences(lines)\n",
        "    sequences = np.array(sequences)\n",
        "\n",
        "    vocab_size = len(tokenizer.word_index) + 1\n",
        "    word_2_index = tokenizer.word_index\n",
        "\n",
        "    X, y = sequences[:, :-1], sequences[:, -1]\n",
        "    y = to_categorical(y, vocab_size)\n",
        "\n",
        "    seq_length = X.shape[1]\n",
        "    print(\"X shape:\", X.shape)\n",
        "    print(\"y shape:\", y.shape)\n",
        "\n",
        "\n",
        "    return generate_texts(model, tokenizer, lines[index], 50, seq_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ihDQcO0RD04",
        "outputId": "a0b14b34-8d4f-4ae7-b01f-fa9d3816da01"
      },
      "source": [
        "sent=test_model(model_kenny, lines, input_length=100, stop_words=stop_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape: (178527, 100)\n",
            "y shape: (178527, 3633)\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "you put them in a group they will be like just they are the worst people like woman who are dating guy you know what i am talking about your boyfriend one on one with you is super emotional they will be like baby i just want to say you mean the world to me baby can you hold my hand while i talk to you can you hold my hand it is almost like the past eight month have become the best eight month can you do that finger thing can we do that finger thing i just want to\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MAcAMuik4ZI",
        "outputId": "7cbee34d-1f14-45eb-bcc6-3e701efb68d5"
      },
      "source": [
        "print(sent[0])\n",
        "print('..........................')\n",
        "print(sent[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['animal', 'sort', 'a', 'admitting', 'in', 'where', 'have', 'insane', 'there', 'can', 'you', 'evil', 'then', 'way', 'want', 'dad', 'restaurant', 'shaving', 'cop', 'late', 'too', 'is', 'dad', 'boil', 'you', 'on', 'a', 'reach', 'left', 'cuz', '26', 'that', 'man', 'initiative', 'caught', 'do', 'it', 'long', 'like', 'bad', 'ha', 'gold', 'bluff', 'so', 'no', 'it', 'to', 'me', 'they', 'boil']\n",
            "..........................\n",
            "['you', 'put', 'them', 'in', 'a', 'group', 'they', 'will', 'be', 'like', 'just', 'they', 'are', 'the', 'worst', 'people', 'like', 'woman', 'who', 'are', 'dating', 'guy', 'you', 'know', 'what', 'i', 'am', 'talking', 'about', 'your', 'boyfriend', 'one', 'on', 'one', 'with', 'you', 'is', 'super', 'emotional', 'they', 'will', 'be', 'like', 'baby', 'i', 'just', 'want', 'to', 'say', 'you', 'mean', 'the', 'world', 'to', 'me', 'baby', 'can', 'you', 'hold', 'my', 'hand', 'while', 'i', 'talk', 'to', 'you', 'can', 'you', 'hold', 'my', 'hand', 'it', 'is', 'almost', 'like', 'the', 'past', 'eight', 'month', 'have', 'become', 'the', 'best', 'eight', 'month', 'can', 'you', 'do', 'that', 'finger', 'thing', 'can', 'we', 'do', 'that', 'finger', 'thing', 'i', 'just', 'want', 'to', 'animal', 'sort', 'a', 'admitting', 'in', 'where', 'have', 'insane', 'there', 'can', 'you', 'evil', 'then', 'way', 'want', 'dad', 'restaurant', 'shaving', 'cop', 'late', 'too', 'is', 'dad', 'boil', 'you', 'on', 'a', 'reach', 'left', 'cuz', '26', 'that', 'man', 'initiative', 'caught', 'do', 'it', 'long', 'like', 'bad', 'ha', 'gold', 'bluff', 'so', 'no', 'it', 'to', 'me', 'they', 'boil']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_X5U5HzzrWFg"
      },
      "source": [
        "def unigram_test(sent):\n",
        "  train_sentences = sent[1]\n",
        "  tokenized_text = [list(map(str.lower, nltk.tokenize.word_tokenize(sent))) \n",
        "                  for sent in train_sentences]\n",
        "  n = 1\n",
        "  train_data, padded_vocab = padded_everygram_pipeline(n, tokenized_text)\n",
        "  model = MLE(n)\n",
        "  model.fit(train_data, padded_vocab)\n",
        "\n",
        "  test_sentences = sent[0]\n",
        "  tokenized_text = [list(map(str.lower, nltk.tokenize.word_tokenize(sent))) \n",
        "                  for sent in test_sentences]\n",
        "\n",
        "  test_data, _ = padded_everygram_pipeline(n, tokenized_text)\n",
        "  for test in test_data:\n",
        "      print (\"MLE Estimates:\", [((ngram[-1], ngram[:-1]),model.score(ngram[-1], ngram[:-1])) for ngram in test])\n",
        "\n",
        "  test_data, _ = padded_everygram_pipeline(n, tokenized_text)\n",
        "\n",
        "  for i, test in enumerate(test_data):\n",
        "    print(\"PP({0}):{1}\".format(test_sentences[i], model.perplexity(test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cFfqIsBFI2w"
      },
      "source": [
        "def bigram_test(sent):\n",
        "  train_sentences = sent[1]\n",
        "  tokenized_text = [list(map(str.lower, nltk.tokenize.word_tokenize(sent))) for sent in train_sentences]\n",
        "\n",
        "  n = 2\n",
        "  train_data = [nltk.bigrams(t,  pad_right=True, pad_left=True, left_pad_symbol=\"<s>\", right_pad_symbol=\"</s>\") for t in tokenized_text]\n",
        "  words = [word for sent in tokenized_text for word in sent]\n",
        "  words.extend([\"<s>\", \"</s>\"])\n",
        "  padded_vocab = Vocabulary(words)\n",
        "  model = MLE(n)\n",
        "  model.fit(train_data, padded_vocab)\n",
        "\n",
        "  test_sentences = sent[0]\n",
        "  tokenized_text = [list(map(str.lower, nltk.tokenize.word_tokenize(sent))) for sent in test_sentences]\n",
        "\n",
        "  test_data = [nltk.bigrams(t,  pad_right=True, pad_left=True, left_pad_symbol=\"<s>\", right_pad_symbol=\"</s>\") for t in tokenized_text]\n",
        "  for test in test_data:\n",
        "      print (\"MLE Estimates:\", [((ngram[-1], ngram[:-1]),model.score(ngram[-1], ngram[:-1])) for ngram in test])\n",
        "\n",
        "  test_data = [nltk.bigrams(t,  pad_right=True, pad_left=True, left_pad_symbol=\"<s>\", right_pad_symbol=\"</s>\") for t in tokenized_text]\n",
        "  for i, test in enumerate(test_data):\n",
        "    print(\"PP({0}):{1}\".format(test_sentences[i], model.perplexity(test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFEc-4woJZMR",
        "outputId": "b99d6437-8656-4238-8abe-f1ebafa5a674"
      },
      "source": [
        "unigram_test(sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLE Estimates: [(('animal', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('sort', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('a', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('admitting', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('in', ()), 0.013245033112582781)]\n",
            "MLE Estimates: [(('where', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('have', ()), 0.013245033112582781)]\n",
            "MLE Estimates: [(('insane', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('there', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('can', ()), 0.033112582781456956)]\n",
            "MLE Estimates: [(('you', ()), 0.06622516556291391)]\n",
            "MLE Estimates: [(('evil', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('then', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('way', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('want', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('dad', ()), 0.013245033112582781)]\n",
            "MLE Estimates: [(('restaurant', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('shaving', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('cop', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('late', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('too', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('is', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('dad', ()), 0.013245033112582781)]\n",
            "MLE Estimates: [(('boil', ()), 0.013245033112582781)]\n",
            "MLE Estimates: [(('you', ()), 0.06622516556291391)]\n",
            "MLE Estimates: [(('on', ()), 0.013245033112582781)]\n",
            "MLE Estimates: [(('a', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('reach', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('left', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('cuz', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('26', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('that', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('man', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('initiative', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('caught', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('do', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('it', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('long', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('like', ()), 0.033112582781456956)]\n",
            "MLE Estimates: [(('bad', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('ha', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('gold', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('bluff', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('so', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('no', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('it', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('to', ()), 0.033112582781456956)]\n",
            "MLE Estimates: [(('me', ()), 0.013245033112582781)]\n",
            "MLE Estimates: [(('they', ()), 0.026490066225165563)]\n",
            "MLE Estimates: [(('boil', ()), 0.013245033112582781)]\n",
            "PP(animal):151.00000000000006\n",
            "PP(sort):151.00000000000006\n",
            "PP(a):50.33333333333336\n",
            "PP(admitting):151.00000000000006\n",
            "PP(in):75.49999999999999\n",
            "PP(where):151.00000000000006\n",
            "PP(have):75.49999999999999\n",
            "PP(insane):151.00000000000006\n",
            "PP(there):151.00000000000006\n",
            "PP(can):30.200000000000006\n",
            "PP(you):15.099999999999998\n",
            "PP(evil):151.00000000000006\n",
            "PP(then):151.00000000000006\n",
            "PP(way):151.00000000000006\n",
            "PP(want):50.33333333333336\n",
            "PP(dad):75.49999999999999\n",
            "PP(restaurant):151.00000000000006\n",
            "PP(shaving):151.00000000000006\n",
            "PP(cop):151.00000000000006\n",
            "PP(late):151.00000000000006\n",
            "PP(too):151.00000000000006\n",
            "PP(is):50.33333333333336\n",
            "PP(dad):75.49999999999999\n",
            "PP(boil):75.49999999999999\n",
            "PP(you):15.099999999999998\n",
            "PP(on):75.49999999999999\n",
            "PP(a):50.33333333333336\n",
            "PP(reach):151.00000000000006\n",
            "PP(left):151.00000000000006\n",
            "PP(cuz):151.00000000000006\n",
            "PP(26):151.00000000000006\n",
            "PP(that):50.33333333333336\n",
            "PP(man):151.00000000000006\n",
            "PP(initiative):151.00000000000006\n",
            "PP(caught):151.00000000000006\n",
            "PP(do):50.33333333333336\n",
            "PP(it):50.33333333333336\n",
            "PP(long):151.00000000000006\n",
            "PP(like):30.200000000000006\n",
            "PP(bad):151.00000000000006\n",
            "PP(ha):151.00000000000006\n",
            "PP(gold):151.00000000000006\n",
            "PP(bluff):151.00000000000006\n",
            "PP(so):151.00000000000006\n",
            "PP(no):151.00000000000006\n",
            "PP(it):50.33333333333336\n",
            "PP(to):30.200000000000006\n",
            "PP(me):75.49999999999999\n",
            "PP(they):37.74999999999999\n",
            "PP(boil):75.49999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSgeRVsUJdra",
        "outputId": "90a4b4ad-fbb2-4909-c3f2-ce26849e2a2f"
      },
      "source": [
        "bigram_test(sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLE Estimates: [(('animal', ('<s>',)), 0.006622516556291391), (('</s>', ('animal',)), 1.0)]\n",
            "MLE Estimates: [(('sort', ('<s>',)), 0.006622516556291391), (('</s>', ('sort',)), 1.0)]\n",
            "MLE Estimates: [(('a', ('<s>',)), 0.019867549668874173), (('</s>', ('a',)), 1.0)]\n",
            "MLE Estimates: [(('admitting', ('<s>',)), 0.006622516556291391), (('</s>', ('admitting',)), 1.0)]\n",
            "MLE Estimates: [(('in', ('<s>',)), 0.013245033112582781), (('</s>', ('in',)), 1.0)]\n",
            "MLE Estimates: [(('where', ('<s>',)), 0.006622516556291391), (('</s>', ('where',)), 1.0)]\n",
            "MLE Estimates: [(('have', ('<s>',)), 0.013245033112582781), (('</s>', ('have',)), 1.0)]\n",
            "MLE Estimates: [(('insane', ('<s>',)), 0.006622516556291391), (('</s>', ('insane',)), 1.0)]\n",
            "MLE Estimates: [(('there', ('<s>',)), 0.006622516556291391), (('</s>', ('there',)), 1.0)]\n",
            "MLE Estimates: [(('can', ('<s>',)), 0.033112582781456956), (('</s>', ('can',)), 1.0)]\n",
            "MLE Estimates: [(('you', ('<s>',)), 0.06622516556291391), (('</s>', ('you',)), 1.0)]\n",
            "MLE Estimates: [(('evil', ('<s>',)), 0.006622516556291391), (('</s>', ('evil',)), 1.0)]\n",
            "MLE Estimates: [(('then', ('<s>',)), 0.006622516556291391), (('</s>', ('then',)), 1.0)]\n",
            "MLE Estimates: [(('way', ('<s>',)), 0.006622516556291391), (('</s>', ('way',)), 1.0)]\n",
            "MLE Estimates: [(('want', ('<s>',)), 0.019867549668874173), (('</s>', ('want',)), 1.0)]\n",
            "MLE Estimates: [(('dad', ('<s>',)), 0.013245033112582781), (('</s>', ('dad',)), 1.0)]\n",
            "MLE Estimates: [(('restaurant', ('<s>',)), 0.006622516556291391), (('</s>', ('restaurant',)), 1.0)]\n",
            "MLE Estimates: [(('shaving', ('<s>',)), 0.006622516556291391), (('</s>', ('shaving',)), 1.0)]\n",
            "MLE Estimates: [(('cop', ('<s>',)), 0.006622516556291391), (('</s>', ('cop',)), 1.0)]\n",
            "MLE Estimates: [(('late', ('<s>',)), 0.006622516556291391), (('</s>', ('late',)), 1.0)]\n",
            "MLE Estimates: [(('too', ('<s>',)), 0.006622516556291391), (('</s>', ('too',)), 1.0)]\n",
            "MLE Estimates: [(('is', ('<s>',)), 0.019867549668874173), (('</s>', ('is',)), 1.0)]\n",
            "MLE Estimates: [(('dad', ('<s>',)), 0.013245033112582781), (('</s>', ('dad',)), 1.0)]\n",
            "MLE Estimates: [(('boil', ('<s>',)), 0.013245033112582781), (('</s>', ('boil',)), 1.0)]\n",
            "MLE Estimates: [(('you', ('<s>',)), 0.06622516556291391), (('</s>', ('you',)), 1.0)]\n",
            "MLE Estimates: [(('on', ('<s>',)), 0.013245033112582781), (('</s>', ('on',)), 1.0)]\n",
            "MLE Estimates: [(('a', ('<s>',)), 0.019867549668874173), (('</s>', ('a',)), 1.0)]\n",
            "MLE Estimates: [(('reach', ('<s>',)), 0.006622516556291391), (('</s>', ('reach',)), 1.0)]\n",
            "MLE Estimates: [(('left', ('<s>',)), 0.006622516556291391), (('</s>', ('left',)), 1.0)]\n",
            "MLE Estimates: [(('cuz', ('<s>',)), 0.006622516556291391), (('</s>', ('cuz',)), 1.0)]\n",
            "MLE Estimates: [(('26', ('<s>',)), 0.006622516556291391), (('</s>', ('26',)), 1.0)]\n",
            "MLE Estimates: [(('that', ('<s>',)), 0.019867549668874173), (('</s>', ('that',)), 1.0)]\n",
            "MLE Estimates: [(('man', ('<s>',)), 0.006622516556291391), (('</s>', ('man',)), 1.0)]\n",
            "MLE Estimates: [(('initiative', ('<s>',)), 0.006622516556291391), (('</s>', ('initiative',)), 1.0)]\n",
            "MLE Estimates: [(('caught', ('<s>',)), 0.006622516556291391), (('</s>', ('caught',)), 1.0)]\n",
            "MLE Estimates: [(('do', ('<s>',)), 0.019867549668874173), (('</s>', ('do',)), 1.0)]\n",
            "MLE Estimates: [(('it', ('<s>',)), 0.019867549668874173), (('</s>', ('it',)), 1.0)]\n",
            "MLE Estimates: [(('long', ('<s>',)), 0.006622516556291391), (('</s>', ('long',)), 1.0)]\n",
            "MLE Estimates: [(('like', ('<s>',)), 0.033112582781456956), (('</s>', ('like',)), 1.0)]\n",
            "MLE Estimates: [(('bad', ('<s>',)), 0.006622516556291391), (('</s>', ('bad',)), 1.0)]\n",
            "MLE Estimates: [(('ha', ('<s>',)), 0.006622516556291391), (('</s>', ('ha',)), 1.0)]\n",
            "MLE Estimates: [(('gold', ('<s>',)), 0.006622516556291391), (('</s>', ('gold',)), 1.0)]\n",
            "MLE Estimates: [(('bluff', ('<s>',)), 0.006622516556291391), (('</s>', ('bluff',)), 1.0)]\n",
            "MLE Estimates: [(('so', ('<s>',)), 0.006622516556291391), (('</s>', ('so',)), 1.0)]\n",
            "MLE Estimates: [(('no', ('<s>',)), 0.006622516556291391), (('</s>', ('no',)), 1.0)]\n",
            "MLE Estimates: [(('it', ('<s>',)), 0.019867549668874173), (('</s>', ('it',)), 1.0)]\n",
            "MLE Estimates: [(('to', ('<s>',)), 0.033112582781456956), (('</s>', ('to',)), 1.0)]\n",
            "MLE Estimates: [(('me', ('<s>',)), 0.013245033112582781), (('</s>', ('me',)), 1.0)]\n",
            "MLE Estimates: [(('they', ('<s>',)), 0.026490066225165563), (('</s>', ('they',)), 1.0)]\n",
            "MLE Estimates: [(('boil', ('<s>',)), 0.013245033112582781), (('</s>', ('boil',)), 1.0)]\n",
            "PP(animal):12.28820572744451\n",
            "PP(sort):12.28820572744451\n",
            "PP(a):7.094598884597589\n",
            "PP(admitting):12.28820572744451\n",
            "PP(in):8.689073598491383\n",
            "PP(where):12.28820572744451\n",
            "PP(have):8.689073598491383\n",
            "PP(insane):12.28820572744451\n",
            "PP(there):12.28820572744451\n",
            "PP(can):5.495452665613635\n",
            "PP(you):3.8858718455450894\n",
            "PP(evil):12.28820572744451\n",
            "PP(then):12.28820572744451\n",
            "PP(way):12.28820572744451\n",
            "PP(want):7.094598884597589\n",
            "PP(dad):8.689073598491383\n",
            "PP(restaurant):12.28820572744451\n",
            "PP(shaving):12.28820572744451\n",
            "PP(cop):12.28820572744451\n",
            "PP(late):12.28820572744451\n",
            "PP(too):12.28820572744451\n",
            "PP(is):7.094598884597589\n",
            "PP(dad):8.689073598491383\n",
            "PP(boil):8.689073598491383\n",
            "PP(you):3.8858718455450894\n",
            "PP(on):8.689073598491383\n",
            "PP(a):7.094598884597589\n",
            "PP(reach):12.28820572744451\n",
            "PP(left):12.28820572744451\n",
            "PP(cuz):12.28820572744451\n",
            "PP(26):12.28820572744451\n",
            "PP(that):7.094598884597589\n",
            "PP(man):12.28820572744451\n",
            "PP(initiative):12.28820572744451\n",
            "PP(caught):12.28820572744451\n",
            "PP(do):7.094598884597589\n",
            "PP(it):7.094598884597589\n",
            "PP(long):12.28820572744451\n",
            "PP(like):5.495452665613635\n",
            "PP(bad):12.28820572744451\n",
            "PP(ha):12.28820572744451\n",
            "PP(gold):12.28820572744451\n",
            "PP(bluff):12.28820572744451\n",
            "PP(so):12.28820572744451\n",
            "PP(no):12.28820572744451\n",
            "PP(it):7.094598884597589\n",
            "PP(to):5.495452665613635\n",
            "PP(me):8.689073598491383\n",
            "PP(they):6.144102863722253\n",
            "PP(boil):8.689073598491383\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRaVCBkhGmtL"
      },
      "source": [
        "model_stop_words = load_model('kenny sebastian_stop_word.h5')\n",
        "model_dropout = load_model('kenny sebastian_stop_word_dropout.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIqBTSFzI2cR",
        "outputId": "b8d44a3c-d217-4908-8df2-5da6f5a76670"
      },
      "source": [
        "sent_stopwords=test_model(model_stop_words, lines, input_length=100, stop_words=stop_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape: (178527, 100)\n",
            "y shape: (178527, 3633)\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "you put them in a group they will be like just they are the worst people like woman who are dating guy you know what i am talking about your boyfriend one on one with you is super emotional they will be like baby i just want to say you mean the world to me baby can you hold my hand while i talk to you can you hold my hand it is almost like the past eight month have become the best eight month can you do that finger thing can we do that finger thing i just want to\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dD9X8HbJuKH",
        "outputId": "6b87d124-59a7-4694-fde4-8582ab9ca462"
      },
      "source": [
        "unigram_test(sent_stopwords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLE Estimates: [(('say', ()), 0.013245033112582781)]\n",
            "MLE Estimates: [(('that', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('my', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('friend', ()), 0.013245033112582781)]\n",
            "MLE Estimates: [(('like', ()), 0.052980132450331126)]\n",
            "MLE Estimates: [(('me', ()), 0.026490066225165563)]\n",
            "MLE Estimates: [(('and', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('gopal', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('have', ()), 0.013245033112582781)]\n",
            "MLE Estimates: [(('been', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('friend', ()), 0.013245033112582781)]\n",
            "MLE Estimates: [(('for', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('like', ()), 0.052980132450331126)]\n",
            "MLE Estimates: [(('eight', ()), 0.026490066225165563)]\n",
            "MLE Estimates: [(('year', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('but', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('your', ()), 0.013245033112582781)]\n",
            "MLE Estimates: [(('eight', ()), 0.026490066225165563)]\n",
            "MLE Estimates: [(('month', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('feel', ()), 0.013245033112582781)]\n",
            "MLE Estimates: [(('like', ()), 0.052980132450331126)]\n",
            "MLE Estimates: [(('a', ()), 0.013245033112582781)]\n",
            "MLE Estimates: [(('life', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('time', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('it', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('is', ()), 0.026490066225165563)]\n",
            "MLE Estimates: [(('not', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('even', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('the', ()), 0.039735099337748346)]\n",
            "MLE Estimates: [(('physical', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('thing', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('it', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('is', ()), 0.026490066225165563)]\n",
            "MLE Estimates: [(('just', ()), 0.026490066225165563)]\n",
            "MLE Estimates: [(('the', ()), 0.039735099337748346)]\n",
            "MLE Estimates: [(('cuddling', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('you', ()), 0.08609271523178808)]\n",
            "MLE Estimates: [(('know', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('you', ()), 0.08609271523178808)]\n",
            "MLE Estimates: [(('make', ()), 0.013245033112582781)]\n",
            "MLE Estimates: [(('me', ()), 0.026490066225165563)]\n",
            "MLE Estimates: [(('you', ()), 0.08609271523178808)]\n",
            "MLE Estimates: [(('make', ()), 0.013245033112582781)]\n",
            "MLE Estimates: [(('me', ()), 0.026490066225165563)]\n",
            "MLE Estimates: [(('feel', ()), 0.013245033112582781)]\n",
            "MLE Estimates: [(('warm', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('you', ()), 0.08609271523178808)]\n",
            "MLE Estimates: [(('know', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('like', ()), 0.052980132450331126)]\n",
            "MLE Estimates: [(('you', ()), 0.08609271523178808)]\n",
            "PP(say):75.49999999999999\n",
            "PP(that):50.33333333333336\n",
            "PP(my):50.33333333333336\n",
            "PP(friend):75.49999999999999\n",
            "PP(like):18.875000000000007\n",
            "PP(me):37.74999999999999\n",
            "PP(and):151.00000000000006\n",
            "PP(gopal):151.00000000000006\n",
            "PP(have):75.49999999999999\n",
            "PP(been):151.00000000000006\n",
            "PP(friend):75.49999999999999\n",
            "PP(for):151.00000000000006\n",
            "PP(like):18.875000000000007\n",
            "PP(eight):37.74999999999999\n",
            "PP(year):151.00000000000006\n",
            "PP(but):151.00000000000006\n",
            "PP(your):75.49999999999999\n",
            "PP(eight):37.74999999999999\n",
            "PP(month):50.33333333333336\n",
            "PP(feel):75.49999999999999\n",
            "PP(like):18.875000000000007\n",
            "PP(a):75.49999999999999\n",
            "PP(life):151.00000000000006\n",
            "PP(time):151.00000000000006\n",
            "PP(it):50.33333333333336\n",
            "PP(is):37.74999999999999\n",
            "PP(not):151.00000000000006\n",
            "PP(even):151.00000000000006\n",
            "PP(the):25.16666666666666\n",
            "PP(physical):151.00000000000006\n",
            "PP(thing):50.33333333333336\n",
            "PP(it):50.33333333333336\n",
            "PP(is):37.74999999999999\n",
            "PP(just):37.74999999999999\n",
            "PP(the):25.16666666666666\n",
            "PP(cuddling):151.00000000000006\n",
            "PP(you):11.615384615384617\n",
            "PP(know):50.33333333333336\n",
            "PP(you):11.615384615384617\n",
            "PP(make):75.49999999999999\n",
            "PP(me):37.74999999999999\n",
            "PP(you):11.615384615384617\n",
            "PP(make):75.49999999999999\n",
            "PP(me):37.74999999999999\n",
            "PP(feel):75.49999999999999\n",
            "PP(warm):151.00000000000006\n",
            "PP(you):11.615384615384617\n",
            "PP(know):50.33333333333336\n",
            "PP(like):18.875000000000007\n",
            "PP(you):11.615384615384617\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiNegq20J_yJ",
        "outputId": "a9bf5148-8250-43a6-d345-54e319166740"
      },
      "source": [
        "bigram_test(sent_stopwords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLE Estimates: [(('say', ('<s>',)), 0.013245033112582781), (('</s>', ('say',)), 1.0)]\n",
            "MLE Estimates: [(('that', ('<s>',)), 0.019867549668874173), (('</s>', ('that',)), 1.0)]\n",
            "MLE Estimates: [(('my', ('<s>',)), 0.019867549668874173), (('</s>', ('my',)), 1.0)]\n",
            "MLE Estimates: [(('friend', ('<s>',)), 0.013245033112582781), (('</s>', ('friend',)), 1.0)]\n",
            "MLE Estimates: [(('like', ('<s>',)), 0.052980132450331126), (('</s>', ('like',)), 1.0)]\n",
            "MLE Estimates: [(('me', ('<s>',)), 0.026490066225165563), (('</s>', ('me',)), 1.0)]\n",
            "MLE Estimates: [(('and', ('<s>',)), 0.006622516556291391), (('</s>', ('and',)), 1.0)]\n",
            "MLE Estimates: [(('gopal', ('<s>',)), 0.006622516556291391), (('</s>', ('gopal',)), 1.0)]\n",
            "MLE Estimates: [(('have', ('<s>',)), 0.013245033112582781), (('</s>', ('have',)), 1.0)]\n",
            "MLE Estimates: [(('been', ('<s>',)), 0.006622516556291391), (('</s>', ('been',)), 1.0)]\n",
            "MLE Estimates: [(('friend', ('<s>',)), 0.013245033112582781), (('</s>', ('friend',)), 1.0)]\n",
            "MLE Estimates: [(('for', ('<s>',)), 0.006622516556291391), (('</s>', ('for',)), 1.0)]\n",
            "MLE Estimates: [(('like', ('<s>',)), 0.052980132450331126), (('</s>', ('like',)), 1.0)]\n",
            "MLE Estimates: [(('eight', ('<s>',)), 0.026490066225165563), (('</s>', ('eight',)), 1.0)]\n",
            "MLE Estimates: [(('year', ('<s>',)), 0.006622516556291391), (('</s>', ('year',)), 1.0)]\n",
            "MLE Estimates: [(('but', ('<s>',)), 0.006622516556291391), (('</s>', ('but',)), 1.0)]\n",
            "MLE Estimates: [(('your', ('<s>',)), 0.013245033112582781), (('</s>', ('your',)), 1.0)]\n",
            "MLE Estimates: [(('eight', ('<s>',)), 0.026490066225165563), (('</s>', ('eight',)), 1.0)]\n",
            "MLE Estimates: [(('month', ('<s>',)), 0.019867549668874173), (('</s>', ('month',)), 1.0)]\n",
            "MLE Estimates: [(('feel', ('<s>',)), 0.013245033112582781), (('</s>', ('feel',)), 1.0)]\n",
            "MLE Estimates: [(('like', ('<s>',)), 0.052980132450331126), (('</s>', ('like',)), 1.0)]\n",
            "MLE Estimates: [(('a', ('<s>',)), 0.013245033112582781), (('</s>', ('a',)), 1.0)]\n",
            "MLE Estimates: [(('life', ('<s>',)), 0.006622516556291391), (('</s>', ('life',)), 1.0)]\n",
            "MLE Estimates: [(('time', ('<s>',)), 0.006622516556291391), (('</s>', ('time',)), 1.0)]\n",
            "MLE Estimates: [(('it', ('<s>',)), 0.019867549668874173), (('</s>', ('it',)), 1.0)]\n",
            "MLE Estimates: [(('is', ('<s>',)), 0.026490066225165563), (('</s>', ('is',)), 1.0)]\n",
            "MLE Estimates: [(('not', ('<s>',)), 0.006622516556291391), (('</s>', ('not',)), 1.0)]\n",
            "MLE Estimates: [(('even', ('<s>',)), 0.006622516556291391), (('</s>', ('even',)), 1.0)]\n",
            "MLE Estimates: [(('the', ('<s>',)), 0.039735099337748346), (('</s>', ('the',)), 1.0)]\n",
            "MLE Estimates: [(('physical', ('<s>',)), 0.006622516556291391), (('</s>', ('physical',)), 1.0)]\n",
            "MLE Estimates: [(('thing', ('<s>',)), 0.019867549668874173), (('</s>', ('thing',)), 1.0)]\n",
            "MLE Estimates: [(('it', ('<s>',)), 0.019867549668874173), (('</s>', ('it',)), 1.0)]\n",
            "MLE Estimates: [(('is', ('<s>',)), 0.026490066225165563), (('</s>', ('is',)), 1.0)]\n",
            "MLE Estimates: [(('just', ('<s>',)), 0.026490066225165563), (('</s>', ('just',)), 1.0)]\n",
            "MLE Estimates: [(('the', ('<s>',)), 0.039735099337748346), (('</s>', ('the',)), 1.0)]\n",
            "MLE Estimates: [(('cuddling', ('<s>',)), 0.006622516556291391), (('</s>', ('cuddling',)), 1.0)]\n",
            "MLE Estimates: [(('you', ('<s>',)), 0.08609271523178808), (('</s>', ('you',)), 1.0)]\n",
            "MLE Estimates: [(('know', ('<s>',)), 0.019867549668874173), (('</s>', ('know',)), 1.0)]\n",
            "MLE Estimates: [(('you', ('<s>',)), 0.08609271523178808), (('</s>', ('you',)), 1.0)]\n",
            "MLE Estimates: [(('make', ('<s>',)), 0.013245033112582781), (('</s>', ('make',)), 1.0)]\n",
            "MLE Estimates: [(('me', ('<s>',)), 0.026490066225165563), (('</s>', ('me',)), 1.0)]\n",
            "MLE Estimates: [(('you', ('<s>',)), 0.08609271523178808), (('</s>', ('you',)), 1.0)]\n",
            "MLE Estimates: [(('make', ('<s>',)), 0.013245033112582781), (('</s>', ('make',)), 1.0)]\n",
            "MLE Estimates: [(('me', ('<s>',)), 0.026490066225165563), (('</s>', ('me',)), 1.0)]\n",
            "MLE Estimates: [(('feel', ('<s>',)), 0.013245033112582781), (('</s>', ('feel',)), 1.0)]\n",
            "MLE Estimates: [(('warm', ('<s>',)), 0.006622516556291391), (('</s>', ('warm',)), 1.0)]\n",
            "MLE Estimates: [(('you', ('<s>',)), 0.08609271523178808), (('</s>', ('you',)), 1.0)]\n",
            "MLE Estimates: [(('know', ('<s>',)), 0.019867549668874173), (('</s>', ('know',)), 1.0)]\n",
            "MLE Estimates: [(('like', ('<s>',)), 0.052980132450331126), (('</s>', ('like',)), 1.0)]\n",
            "MLE Estimates: [(('you', ('<s>',)), 0.08609271523178808), (('</s>', ('you',)), 1.0)]\n",
            "PP(say):8.689073598491383\n",
            "PP(that):7.094598884597589\n",
            "PP(my):7.094598884597589\n",
            "PP(friend):8.689073598491383\n",
            "PP(like):4.3445367992456925\n",
            "PP(me):6.144102863722253\n",
            "PP(and):12.28820572744451\n",
            "PP(gopal):12.28820572744451\n",
            "PP(have):8.689073598491383\n",
            "PP(been):12.28820572744451\n",
            "PP(friend):8.689073598491383\n",
            "PP(for):12.28820572744451\n",
            "PP(like):4.3445367992456925\n",
            "PP(eight):6.144102863722253\n",
            "PP(year):12.28820572744451\n",
            "PP(but):12.28820572744451\n",
            "PP(your):8.689073598491383\n",
            "PP(eight):6.144102863722253\n",
            "PP(month):7.094598884597589\n",
            "PP(feel):8.689073598491383\n",
            "PP(like):4.3445367992456925\n",
            "PP(a):8.689073598491383\n",
            "PP(life):12.28820572744451\n",
            "PP(time):12.28820572744451\n",
            "PP(it):7.094598884597589\n",
            "PP(is):6.144102863722253\n",
            "PP(not):12.28820572744451\n",
            "PP(even):12.28820572744451\n",
            "PP(the):5.01663898109747\n",
            "PP(physical):12.28820572744451\n",
            "PP(thing):7.094598884597589\n",
            "PP(it):7.094598884597589\n",
            "PP(is):6.144102863722253\n",
            "PP(just):6.144102863722253\n",
            "PP(the):5.01663898109747\n",
            "PP(cuddling):12.28820572744451\n",
            "PP(you):3.4081350641347266\n",
            "PP(know):7.094598884597589\n",
            "PP(you):3.4081350641347266\n",
            "PP(make):8.689073598491383\n",
            "PP(me):6.144102863722253\n",
            "PP(you):3.4081350641347266\n",
            "PP(make):8.689073598491383\n",
            "PP(me):6.144102863722253\n",
            "PP(feel):8.689073598491383\n",
            "PP(warm):12.28820572744451\n",
            "PP(you):3.4081350641347266\n",
            "PP(know):7.094598884597589\n",
            "PP(like):4.3445367992456925\n",
            "PP(you):3.4081350641347266\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jocm8J4lKE-f",
        "outputId": "73081b16-952f-409b-a5c0-1d0f2f7f0677"
      },
      "source": [
        "sent_dropout=test_model(model_dropout, lines, input_length=100, stop_words=stop_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape: (178527, 100)\n",
            "y shape: (178527, 3633)\n",
            "______________________________________________________________________________________________________________________________________________________\n",
            "you put them in a group they will be like just they are the worst people like woman who are dating guy you know what i am talking about your boyfriend one on one with you is super emotional they will be like baby i just want to say you mean the world to me baby can you hold my hand while i talk to you can you hold my hand it is almost like the past eight month have become the best eight month can you do that finger thing can we do that finger thing i just want to\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZM2JdycKjWo",
        "outputId": "c77219fb-f492-4bb9-9623-1f7f9871cae0"
      },
      "source": [
        "unigram_test(sent_dropout)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLE Estimates: [(('say', ()), 0.013245033112582781)]\n",
            "MLE Estimates: [(('that', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('my', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('friend', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('is', ()), 0.026490066225165563)]\n",
            "MLE Estimates: [(('me', ()), 0.013245033112582781)]\n",
            "MLE Estimates: [(('and', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('then', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('vegetarian', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('version', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('of', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('this', ()), 0.006622516556291391)]\n",
            "MLE Estimates: [(('is', ()), 0.026490066225165563)]\n",
            "MLE Estimates: [(('cottage', ()), 0.026490066225165563)]\n",
            "MLE Estimates: [(('cheese', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('no', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('one', ()), 0.033112582781456956)]\n",
            "MLE Estimates: [(('give', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('you', ()), 0.09271523178807947)]\n",
            "MLE Estimates: [(('any', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('respect', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('if', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('you', ()), 0.09271523178807947)]\n",
            "MLE Estimates: [(('can', ()), 0.046357615894039736)]\n",
            "MLE Estimates: [(('cook', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('cottage', ()), 0.026490066225165563)]\n",
            "MLE Estimates: [(('cheese', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('no', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('one', ()), 0.033112582781456956)]\n",
            "MLE Estimates: [(('give', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('you', ()), 0.09271523178807947)]\n",
            "MLE Estimates: [(('any', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('respect', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('if', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('you', ()), 0.09271523178807947)]\n",
            "MLE Estimates: [(('can', ()), 0.046357615894039736)]\n",
            "MLE Estimates: [(('cook', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('cottage', ()), 0.026490066225165563)]\n",
            "MLE Estimates: [(('cheese', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('no', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('one', ()), 0.033112582781456956)]\n",
            "MLE Estimates: [(('give', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('you', ()), 0.09271523178807947)]\n",
            "MLE Estimates: [(('any', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('respect', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('if', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('you', ()), 0.09271523178807947)]\n",
            "MLE Estimates: [(('can', ()), 0.046357615894039736)]\n",
            "MLE Estimates: [(('cook', ()), 0.019867549668874173)]\n",
            "MLE Estimates: [(('cottage', ()), 0.026490066225165563)]\n",
            "PP(say):75.49999999999999\n",
            "PP(that):50.33333333333336\n",
            "PP(my):50.33333333333336\n",
            "PP(friend):151.00000000000006\n",
            "PP(is):37.74999999999999\n",
            "PP(me):75.49999999999999\n",
            "PP(and):151.00000000000006\n",
            "PP(then):151.00000000000006\n",
            "PP(vegetarian):151.00000000000006\n",
            "PP(version):151.00000000000006\n",
            "PP(of):151.00000000000006\n",
            "PP(this):151.00000000000006\n",
            "PP(is):37.74999999999999\n",
            "PP(cottage):37.74999999999999\n",
            "PP(cheese):50.33333333333336\n",
            "PP(no):50.33333333333336\n",
            "PP(one):30.200000000000006\n",
            "PP(give):50.33333333333336\n",
            "PP(you):10.78571428571429\n",
            "PP(any):50.33333333333336\n",
            "PP(respect):50.33333333333336\n",
            "PP(if):50.33333333333336\n",
            "PP(you):10.78571428571429\n",
            "PP(can):21.571428571428573\n",
            "PP(cook):50.33333333333336\n",
            "PP(cottage):37.74999999999999\n",
            "PP(cheese):50.33333333333336\n",
            "PP(no):50.33333333333336\n",
            "PP(one):30.200000000000006\n",
            "PP(give):50.33333333333336\n",
            "PP(you):10.78571428571429\n",
            "PP(any):50.33333333333336\n",
            "PP(respect):50.33333333333336\n",
            "PP(if):50.33333333333336\n",
            "PP(you):10.78571428571429\n",
            "PP(can):21.571428571428573\n",
            "PP(cook):50.33333333333336\n",
            "PP(cottage):37.74999999999999\n",
            "PP(cheese):50.33333333333336\n",
            "PP(no):50.33333333333336\n",
            "PP(one):30.200000000000006\n",
            "PP(give):50.33333333333336\n",
            "PP(you):10.78571428571429\n",
            "PP(any):50.33333333333336\n",
            "PP(respect):50.33333333333336\n",
            "PP(if):50.33333333333336\n",
            "PP(you):10.78571428571429\n",
            "PP(can):21.571428571428573\n",
            "PP(cook):50.33333333333336\n",
            "PP(cottage):37.74999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2DmKJThKUNc",
        "outputId": "a9365423-22c0-4dc8-ec75-d1c3efe74f23"
      },
      "source": [
        "bigram_test(sent_dropout)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLE Estimates: [(('say', ('<s>',)), 0.013245033112582781), (('</s>', ('say',)), 1.0)]\n",
            "MLE Estimates: [(('that', ('<s>',)), 0.019867549668874173), (('</s>', ('that',)), 1.0)]\n",
            "MLE Estimates: [(('my', ('<s>',)), 0.019867549668874173), (('</s>', ('my',)), 1.0)]\n",
            "MLE Estimates: [(('friend', ('<s>',)), 0.006622516556291391), (('</s>', ('friend',)), 1.0)]\n",
            "MLE Estimates: [(('is', ('<s>',)), 0.026490066225165563), (('</s>', ('is',)), 1.0)]\n",
            "MLE Estimates: [(('me', ('<s>',)), 0.013245033112582781), (('</s>', ('me',)), 1.0)]\n",
            "MLE Estimates: [(('and', ('<s>',)), 0.006622516556291391), (('</s>', ('and',)), 1.0)]\n",
            "MLE Estimates: [(('then', ('<s>',)), 0.006622516556291391), (('</s>', ('then',)), 1.0)]\n",
            "MLE Estimates: [(('vegetarian', ('<s>',)), 0.006622516556291391), (('</s>', ('vegetarian',)), 1.0)]\n",
            "MLE Estimates: [(('version', ('<s>',)), 0.006622516556291391), (('</s>', ('version',)), 1.0)]\n",
            "MLE Estimates: [(('of', ('<s>',)), 0.006622516556291391), (('</s>', ('of',)), 1.0)]\n",
            "MLE Estimates: [(('this', ('<s>',)), 0.006622516556291391), (('</s>', ('this',)), 1.0)]\n",
            "MLE Estimates: [(('is', ('<s>',)), 0.026490066225165563), (('</s>', ('is',)), 1.0)]\n",
            "MLE Estimates: [(('cottage', ('<s>',)), 0.026490066225165563), (('</s>', ('cottage',)), 1.0)]\n",
            "MLE Estimates: [(('cheese', ('<s>',)), 0.019867549668874173), (('</s>', ('cheese',)), 1.0)]\n",
            "MLE Estimates: [(('no', ('<s>',)), 0.019867549668874173), (('</s>', ('no',)), 1.0)]\n",
            "MLE Estimates: [(('one', ('<s>',)), 0.033112582781456956), (('</s>', ('one',)), 1.0)]\n",
            "MLE Estimates: [(('give', ('<s>',)), 0.019867549668874173), (('</s>', ('give',)), 1.0)]\n",
            "MLE Estimates: [(('you', ('<s>',)), 0.09271523178807947), (('</s>', ('you',)), 1.0)]\n",
            "MLE Estimates: [(('any', ('<s>',)), 0.019867549668874173), (('</s>', ('any',)), 1.0)]\n",
            "MLE Estimates: [(('respect', ('<s>',)), 0.019867549668874173), (('</s>', ('respect',)), 1.0)]\n",
            "MLE Estimates: [(('if', ('<s>',)), 0.019867549668874173), (('</s>', ('if',)), 1.0)]\n",
            "MLE Estimates: [(('you', ('<s>',)), 0.09271523178807947), (('</s>', ('you',)), 1.0)]\n",
            "MLE Estimates: [(('can', ('<s>',)), 0.046357615894039736), (('</s>', ('can',)), 1.0)]\n",
            "MLE Estimates: [(('cook', ('<s>',)), 0.019867549668874173), (('</s>', ('cook',)), 1.0)]\n",
            "MLE Estimates: [(('cottage', ('<s>',)), 0.026490066225165563), (('</s>', ('cottage',)), 1.0)]\n",
            "MLE Estimates: [(('cheese', ('<s>',)), 0.019867549668874173), (('</s>', ('cheese',)), 1.0)]\n",
            "MLE Estimates: [(('no', ('<s>',)), 0.019867549668874173), (('</s>', ('no',)), 1.0)]\n",
            "MLE Estimates: [(('one', ('<s>',)), 0.033112582781456956), (('</s>', ('one',)), 1.0)]\n",
            "MLE Estimates: [(('give', ('<s>',)), 0.019867549668874173), (('</s>', ('give',)), 1.0)]\n",
            "MLE Estimates: [(('you', ('<s>',)), 0.09271523178807947), (('</s>', ('you',)), 1.0)]\n",
            "MLE Estimates: [(('any', ('<s>',)), 0.019867549668874173), (('</s>', ('any',)), 1.0)]\n",
            "MLE Estimates: [(('respect', ('<s>',)), 0.019867549668874173), (('</s>', ('respect',)), 1.0)]\n",
            "MLE Estimates: [(('if', ('<s>',)), 0.019867549668874173), (('</s>', ('if',)), 1.0)]\n",
            "MLE Estimates: [(('you', ('<s>',)), 0.09271523178807947), (('</s>', ('you',)), 1.0)]\n",
            "MLE Estimates: [(('can', ('<s>',)), 0.046357615894039736), (('</s>', ('can',)), 1.0)]\n",
            "MLE Estimates: [(('cook', ('<s>',)), 0.019867549668874173), (('</s>', ('cook',)), 1.0)]\n",
            "MLE Estimates: [(('cottage', ('<s>',)), 0.026490066225165563), (('</s>', ('cottage',)), 1.0)]\n",
            "MLE Estimates: [(('cheese', ('<s>',)), 0.019867549668874173), (('</s>', ('cheese',)), 1.0)]\n",
            "MLE Estimates: [(('no', ('<s>',)), 0.019867549668874173), (('</s>', ('no',)), 1.0)]\n",
            "MLE Estimates: [(('one', ('<s>',)), 0.033112582781456956), (('</s>', ('one',)), 1.0)]\n",
            "MLE Estimates: [(('give', ('<s>',)), 0.019867549668874173), (('</s>', ('give',)), 1.0)]\n",
            "MLE Estimates: [(('you', ('<s>',)), 0.09271523178807947), (('</s>', ('you',)), 1.0)]\n",
            "MLE Estimates: [(('any', ('<s>',)), 0.019867549668874173), (('</s>', ('any',)), 1.0)]\n",
            "MLE Estimates: [(('respect', ('<s>',)), 0.019867549668874173), (('</s>', ('respect',)), 1.0)]\n",
            "MLE Estimates: [(('if', ('<s>',)), 0.019867549668874173), (('</s>', ('if',)), 1.0)]\n",
            "MLE Estimates: [(('you', ('<s>',)), 0.09271523178807947), (('</s>', ('you',)), 1.0)]\n",
            "MLE Estimates: [(('can', ('<s>',)), 0.046357615894039736), (('</s>', ('can',)), 1.0)]\n",
            "MLE Estimates: [(('cook', ('<s>',)), 0.019867549668874173), (('</s>', ('cook',)), 1.0)]\n",
            "MLE Estimates: [(('cottage', ('<s>',)), 0.026490066225165563), (('</s>', ('cottage',)), 1.0)]\n",
            "PP(say):8.689073598491383\n",
            "PP(that):7.094598884597589\n",
            "PP(my):7.094598884597589\n",
            "PP(friend):12.28820572744451\n",
            "PP(is):6.144102863722253\n",
            "PP(me):8.689073598491383\n",
            "PP(and):12.28820572744451\n",
            "PP(then):12.28820572744451\n",
            "PP(vegetarian):12.28820572744451\n",
            "PP(version):12.28820572744451\n",
            "PP(of):12.28820572744451\n",
            "PP(this):12.28820572744451\n",
            "PP(is):6.144102863722253\n",
            "PP(cottage):6.144102863722253\n",
            "PP(cheese):7.094598884597589\n",
            "PP(no):7.094598884597589\n",
            "PP(one):5.495452665613635\n",
            "PP(give):7.094598884597589\n",
            "PP(you):3.284161123592186\n",
            "PP(any):7.094598884597589\n",
            "PP(respect):7.094598884597589\n",
            "PP(if):7.094598884597589\n",
            "PP(you):3.284161123592186\n",
            "PP(can):4.644505202002531\n",
            "PP(cook):7.094598884597589\n",
            "PP(cottage):6.144102863722253\n",
            "PP(cheese):7.094598884597589\n",
            "PP(no):7.094598884597589\n",
            "PP(one):5.495452665613635\n",
            "PP(give):7.094598884597589\n",
            "PP(you):3.284161123592186\n",
            "PP(any):7.094598884597589\n",
            "PP(respect):7.094598884597589\n",
            "PP(if):7.094598884597589\n",
            "PP(you):3.284161123592186\n",
            "PP(can):4.644505202002531\n",
            "PP(cook):7.094598884597589\n",
            "PP(cottage):6.144102863722253\n",
            "PP(cheese):7.094598884597589\n",
            "PP(no):7.094598884597589\n",
            "PP(one):5.495452665613635\n",
            "PP(give):7.094598884597589\n",
            "PP(you):3.284161123592186\n",
            "PP(any):7.094598884597589\n",
            "PP(respect):7.094598884597589\n",
            "PP(if):7.094598884597589\n",
            "PP(you):3.284161123592186\n",
            "PP(can):4.644505202002531\n",
            "PP(cook):7.094598884597589\n",
            "PP(cottage):6.144102863722253\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXcoKi8YMpx8"
      },
      "source": [
        "\n",
        "\n",
        "import itertools\n",
        "\n",
        "#supporting function\n",
        "def _split_into_words(sentences):\n",
        "  \"\"\"Splits multiple sentences into words and flattens the result\"\"\"\n",
        "  return list(itertools.chain(*[_.split(\" \") for _ in sentences]))\n",
        "\n",
        "#supporting function\n",
        "def _get_word_ngrams(n, sentences):\n",
        "  \"\"\"Calculates word n-grams for multiple sentences.\n",
        "  \"\"\"\n",
        "  assert len(sentences) > 0\n",
        "  assert n > 0\n",
        "\n",
        "  words = _split_into_words(sentences)\n",
        "  return _get_ngrams(n, words)\n",
        "\n",
        "#supporting function\n",
        "def _get_ngrams(n, text):\n",
        "  \"\"\"Calcualtes n-grams.\n",
        "  Args:\n",
        "    n: which n-grams to calculate\n",
        "    text: An array of tokens\n",
        "  Returns:\n",
        "    A set of n-grams\n",
        "  \"\"\"\n",
        "  ngram_set = set()\n",
        "  text_length = len(text)\n",
        "  max_index_ngram_start = text_length - n\n",
        "  for i in range(max_index_ngram_start + 1):\n",
        "    ngram_set.add(tuple(text[i:i + n]))\n",
        "  return ngram_set\n",
        "\n",
        "def rouge_n(reference_sentences, evaluated_sentences, n=2):\n",
        "  \"\"\"\n",
        "  Computes ROUGE-N of two text collections of sentences.\n",
        "  \n",
        "  Args:\n",
        "    evaluated_sentences: The sentences that have been picked by the summarizer\n",
        "    reference_sentences: The sentences from the referene set\n",
        "    n: Size of ngram.  Defaults to 2.\n",
        "  Returns:\n",
        "    recall rouge score(float)\n",
        "  Raises:\n",
        "    ValueError: raises exception if a param has len <= 0\n",
        "  \"\"\"\n",
        "  if len(evaluated_sentences) <= 0 or len(reference_sentences) <= 0:\n",
        "    raise ValueError(\"Collections must contain at least 1 sentence.\")\n",
        "\n",
        "  evaluated_ngrams = _get_word_ngrams(n, evaluated_sentences)\n",
        "  reference_ngrams = _get_word_ngrams(n, reference_sentences)\n",
        "  reference_count = len(reference_ngrams)\n",
        "  evaluated_count = len(evaluated_ngrams)\n",
        "\n",
        "  # Gets the overlapping ngrams between evaluated and reference\n",
        "  overlapping_ngrams = evaluated_ngrams.intersection(reference_ngrams)\n",
        "  overlapping_count = len(overlapping_ngrams)\n",
        "\n",
        "  # Handle edge case. This isn't mathematically correct, but it's good enough\n",
        "  if evaluated_count == 0:\n",
        "    precision = 0.0\n",
        "  else:\n",
        "    precision = overlapping_count / evaluated_count\n",
        "\n",
        "  if reference_count == 0:\n",
        "    recall = 0.0\n",
        "  else:\n",
        "    recall = overlapping_count / reference_count\n",
        "\n",
        "  f1_score = 2.0 * ((precision * recall) / (precision + recall + 1e-8))\n",
        "\n",
        "  #just returning recall count in rouge, useful for our purpose\n",
        "  return recall"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RyjG_1aM0kq"
      },
      "source": [
        "ref=sent[1]\n",
        "gen=sent[0]\n",
        "d={}\n",
        "d['sentence'] = rouge_n(ref, gen, n=2)\n",
        "rouge_score\n",
        "ref=sent_stopwords[1]\n",
        "gen=sent_stopwords[0]\n",
        "d['sentence_with_stopwords'] = rouge_n(ref, gen, n=2)\n",
        "ref=sent_dropout[1]\n",
        "gen=sent_dropout[0]\n",
        "d['sentence_with_dropout'] = rouge_n(ref, gen, n=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mausAROJOnf2",
        "outputId": "0633ba2a-539a-4e6c-8297-c1d1b3b6d928"
      },
      "source": [
        "d"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentence': 0.3684210526315789,\n",
              " 'sentence_with_dropout': 0.22935779816513763,\n",
              " 'sentence_with_stopwords': 0.3543307086614173}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypa7NRhmxTJW"
      },
      "source": [
        "def cosine_similarity(t1,t2):\n",
        "  X_list = t1\n",
        "  Y_list = t2\n",
        "\n",
        "  l1 =[];l2 =[]\n",
        "  X_set = {w for w in X_list} \n",
        "  Y_set = {w for w in Y_list}\n",
        "  rvector = X_set.union(Y_set) \n",
        "  for w in rvector:\n",
        "      if w in X_set: l1.append(1) # create a vector\n",
        "      else: l1.append(0)\n",
        "      if w in Y_set: l2.append(1)\n",
        "      else: l2.append(0)\n",
        "  c = 0\n",
        "    \n",
        "  # cosine formula \n",
        "  for i in range(len(rvector)):\n",
        "          c+= l1[i]*l2[i]\n",
        "  cosine = c / float((sum(l1)*sum(l2))**0.5)\n",
        "  return cosine\n",
        "  print(\"similarity: \", cosine)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4giWo4AqsdOb",
        "outputId": "9fff1f82-112b-4fd1-bd73-0aac8d1eb9ac"
      },
      "source": [
        "cosine_sentence=cosine_similarity(sent[1],sent[0])\n",
        "cosine_stopwords=cosine_similarity(sent_stopwords[1],sent_stopwords[0])\n",
        "cosine_dropout=cosine_similarity(sent_dropout[1],sent_dropout[0])\n",
        "print(\"Sentence similarity: \", cosine_sentence)\n",
        "print(\"Sentence similarity with stopwords: \", cosine_stopwords)\n",
        "print(\"Sentence similarity with dropout: \", cosine_dropout)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence similarity:  0.6460582824697986\n",
            "Sentence similarity with stopwords:  0.6460582824697986\n",
            "Sentence similarity with dropout:  0.6460582824697986\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}